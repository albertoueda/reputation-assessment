{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CN-Infocom Clusters\n",
    "\n",
    "created on 2016-04-04 by Alberto Ueda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mmap\n",
    "import time\n",
    "import re\n",
    "\n",
    "from unidecode import unidecode\n",
    "UTF8 = 'utf-8'        \n",
    "\n",
    "class Dict(dict):\n",
    "    def __missing__(self, key):\n",
    "            return False\n",
    "\n",
    "#reload(sys)  # Solve the acentos problem, but create the terminal output problem\n",
    "#sys.setdefaultencoding(UTF8)\n",
    "\n",
    "mypath = '/mnt/hd0/alberto/Dropbox/ufmg-not-code/datasets/dblp/cn-infocom-clusters/' # UFMG\n",
    "# mypath = '/home/alberto/Dropbox/ufmg-not-code/datasets/dblp/cn-infocom-clusters/' # Home"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Coauthors (Must be executed once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highest_author_id:  79800\n",
      "Processed 0 rows of coauthorship...\n",
      "Coauthors loaded.\n"
     ]
    }
   ],
   "source": [
    "# Filtering by number of publications\n",
    "min_publications = 20\n",
    "a_num_papers = pd.read_csv(mypath + '../author_num_papers.csv')\n",
    "filtered_authors = a_num_papers[a_num_papers['n_papers'] > min_publications]['author'].tolist()\n",
    "highest_author_id = len(filtered_authors)\n",
    "print ('highest_author_id: ', highest_author_id)\n",
    "\n",
    "# Load coauthors   # full exec. time ~2min\n",
    "max_coauthors = 100\n",
    "# highest_author_id = 170049\n",
    "\n",
    "coauthors = Dict()\n",
    "with open(mypath + '../author-coauthors.tsv') as f:        \n",
    "    k = 0    \n",
    "    for line in f.readlines():          \n",
    "        if k % 100000 == 0: print ('Processed', k , 'rows of coauthorship...')    \n",
    "        k+=1       \n",
    "        \n",
    "        authors = line.split()        \n",
    "        author = int(authors[0])\n",
    "        \n",
    "        if (author > highest_author_id): break\n",
    "        \n",
    "        # Limiting the max number of coauthors\n",
    "        max_coauthors = max_coauthors if len(authors) > max_coauthors else len(authors)\n",
    "        \n",
    "        for i in range(1, len(authors)): #len(authors) (unlimited) or max_coauthors             \n",
    "            coauthor = int(authors[i])\n",
    "            \n",
    "            if (coauthor > highest_author_id): continue\n",
    "                \n",
    "            if coauthors[author] == False: coauthors[author] = []            \n",
    "            coauthors[author].append(coauthor)    \n",
    "\n",
    "print ('Coauthors loaded.')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering by Venue (Bash)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# One-line Command (Computer Networks)\n",
    "grep -n 'journals/cn/' ../papers.csv > tmp && sed -i -- 's/:/\\t/g' tmp && awk '{$1=$1-1} {print}' tmp > tmp2 && sed -i -- 's/\\ /\\t/g' tmp2 && mkdir cn && mv tmp2 cn/papers.csv.cn && rm tmp*\n",
    "\n",
    "# WSDM\n",
    "grep -n 'conf/wsdm/' ../papers.csv > tmp && sed -i -- 's/:/\\t/g' tmp && awk '{$1=$1-1} {print}' tmp > tmp2 && sed -i -- 's/\\ /\\t/g' tmp2 && mkdir wsdm && mv tmp2 wsdm/papers.csv.wsdm && rm tmp*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Venue Authors Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "venue_p:\n",
      "    paper                    conf  year    x\n",
      "0   5025       conf/wsdm/LuXKY14  2014  994\n",
      "1   5292     conf/wsdm/ZhangKY14  2014  994\n",
      "2   5554  conf/wsdm/AgarwalLTY08  2008  994\n",
      "3   5680      conf/wsdm/DingLY08  2008  994\n",
      "4   5758    conf/wsdm/ZhangWWY13  2013  994 \n",
      "\n",
      "venue_a_unique:\n",
      "         id                label  score\n",
      "95   11005             Yi Chang     11\n",
      "494   1090           Ravi Kumar     11\n",
      "858   3467      Susan T. Dumais     11\n",
      "621  17346  Sreenivas Gollapudi     10\n",
      "700   9326     Vanja Josifovski     10\n"
     ]
    }
   ],
   "source": [
    "venue_name = 'wsdm'\n",
    "\n",
    "venue_top_authors_file = venue_name + '_authors.csv.sorted'\n",
    "output_path = mypath + venue_name + '/'\n",
    "\n",
    "a_p = pd.read_csv(mypath + \"../authorpaper.csv\", names=['author','paper'])#, nrows=17220)\n",
    "all_names = pd.read_csv(mypath + \"../all_names.csv\")\n",
    "venue_p = pd.read_csv(output_path + \"papers.csv.\" + venue_name, header=None, names=['paper', 'conf', 'year', 'x'], sep='\\t')#, nrows=17220)\n",
    "print ('venue_p:\\n', venue_p.head(), '\\n')\n",
    "\n",
    "venue_a = pd.merge(venue_p, a_p, how='left', on='paper')\n",
    "venue_a = pd.merge(venue_a, all_names, left_on='author', right_on='id', how='left')\n",
    "venue_a_unique = venue_a[['id','label']].drop_duplicates()\n",
    "\n",
    "for index, row in venue_a_unique.iterrows(): # try to use 'apply' later :)   \n",
    "    a_score = len(venue_a[venue_a['id'] == row['id']])       \n",
    "    venue_a_unique.set_value(index, 'score', a_score)\n",
    "    \n",
    "venue_a_unique.sort_values(by='score', inplace=True, ascending=False)\n",
    "venue_a_unique.to_csv(output_path + venue_top_authors_file, index=False)\n",
    "print ('venue_a_unique:\\n', venue_a_unique.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper</th>\n",
       "      <th>conf</th>\n",
       "      <th>year</th>\n",
       "      <th>x</th>\n",
       "      <th>author</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5025</td>\n",
       "      <td>conf/wsdm/LuXKY14</td>\n",
       "      <td>2014</td>\n",
       "      <td>994</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Philip S. Yu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5025</td>\n",
       "      <td>conf/wsdm/LuXKY14</td>\n",
       "      <td>2014</td>\n",
       "      <td>994</td>\n",
       "      <td>25868</td>\n",
       "      <td>25868</td>\n",
       "      <td>Xiangnan Kong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5025</td>\n",
       "      <td>conf/wsdm/LuXKY14</td>\n",
       "      <td>2014</td>\n",
       "      <td>994</td>\n",
       "      <td>76555</td>\n",
       "      <td>76555</td>\n",
       "      <td>Sihong Xie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5025</td>\n",
       "      <td>conf/wsdm/LuXKY14</td>\n",
       "      <td>2014</td>\n",
       "      <td>994</td>\n",
       "      <td>491641</td>\n",
       "      <td>491641</td>\n",
       "      <td>Chun-Ta Lu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5292</td>\n",
       "      <td>conf/wsdm/ZhangKY14</td>\n",
       "      <td>2014</td>\n",
       "      <td>994</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Philip S. Yu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paper                 conf  year    x  author      id          label\n",
       "0   5025    conf/wsdm/LuXKY14  2014  994       5       5   Philip S. Yu\n",
       "1   5025    conf/wsdm/LuXKY14  2014  994   25868   25868  Xiangnan Kong\n",
       "2   5025    conf/wsdm/LuXKY14  2014  994   76555   76555     Sihong Xie\n",
       "3   5025    conf/wsdm/LuXKY14  2014  994  491641  491641     Chun-Ta Lu\n",
       "4   5292  conf/wsdm/ZhangKY14  2014  994       5       5   Philip S. Yu"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "venue_a.head() # Authors id and label check "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the Graph of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing coauthorship edges [ wsdm ]...\n",
      "Writing authors nodes...\n",
      "Assigning the correct weights to the edges...\n",
      "Generating MCL input...\n",
      "N: 3179  E: 4891\n",
      "Process has finished.\n"
     ]
    }
   ],
   "source": [
    "n_top_authors = 50\n",
    "levels = 2\n",
    "tmp_file = 'tmp'\n",
    "\n",
    "# Selecting the first n top authors\n",
    "top_authors = pd.read_csv(output_path + venue_top_authors_file)\n",
    "list_venue_top_a = top_authors['id'].head(n_top_authors).tolist()\n",
    "# or by author id\n",
    "# list_top = top_authors[top_authors['label'].str.contains('Edmundo')]['id'].head(n_authors).tolist()\n",
    "print (\"Writing coauthorship edges [\", venue_name, \"]...\")\n",
    "\n",
    "with open(output_path + tmp_file, 'w') as f:        \n",
    "    found = Dict()        \n",
    "    all_authors_found = []\n",
    "    new_authors = list_venue_top_a    \n",
    "    f.write('SOURCE,TARGET,TYPE\\n')\n",
    "        \n",
    "    for i in range(1, levels):\n",
    "        #f.write('\\nlevel:' + str(i+1) + '\\n')\n",
    "        authors = new_authors\n",
    "        new_authors = []\n",
    "\n",
    "        for author in authors:            \n",
    "            if coauthors[author] == False or found[author] == True: continue           \n",
    "            all_authors_found.append(author)    \n",
    "\n",
    "            for coauthor in coauthors[author]:      \n",
    "                \n",
    "                # Left ID always lower than Right ID\n",
    "                if (author < coauthor):\n",
    "                    f.write(str(author) + ',' + str(coauthor) + ',Undirected\\n')\n",
    "                else:\n",
    "                    f.write(str(coauthor) + ',' + str(author) + ',Undirected\\n')\n",
    "                    \n",
    "                new_authors.append(coauthor)   \n",
    "                all_authors_found.append(coauthor)\n",
    "\n",
    "            # if (author > highest_author_id): print ('Warning: the author should not be here:', author)\n",
    "            found[author] = True\n",
    "\n",
    "\n",
    "# Names of the authors of interest; highlighting the top authors from the list\n",
    "print (\"Writing authors nodes...\")\n",
    "nodes = pd.read_csv(mypath + \"../all_names.csv\")\n",
    "nodes = nodes[nodes['id'].isin(all_authors_found)]\n",
    "nodes['top'] = 0\n",
    "nodes.ix[nodes['id'].isin(list_venue_top_a), 'top'] = 1\n",
    "nodes.to_csv(output_path + \"nodes.csv\", index=False)     \n",
    "\n",
    "# Edge Weights (based on number of coauthorships)\n",
    "print (\"Assigning the correct weights to the edges...\")\n",
    "weights = pd.read_csv(mypath + '../coauthorships.csv', names=['SOURCE', 'TARGET', 'WEIGHT'], skiprows=1)\n",
    "edges = pd.read_csv(output_path + tmp_file)\n",
    "\n",
    "# We could apply functions to balance the weights\n",
    "weights['WEIGHT'] = weights['WEIGHT'].apply(lambda x: (log(x) + 1))\n",
    "\n",
    "edges = pd.merge(edges, weights)\n",
    "edges.drop_duplicates(inplace=True)\n",
    "edges.to_csv(output_path + 'edges.csv', index=False)\n",
    "\n",
    "# MCL Input\n",
    "print (\"Generating MCL input...\")\n",
    "edges[['SOURCE', 'TARGET', 'WEIGHT']].to_csv(output_path + 'mcl_input.txt', index=False, header=None, sep=' ')\n",
    "\n",
    "print (\"N:\", len(nodes), \" E:\", len(edges))\n",
    "print (\"Process has finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reweighting only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOURCE</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>WEIGHT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>211</td>\n",
       "      <td>Undirected</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>211</td>\n",
       "      <td>Undirected</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98</td>\n",
       "      <td>211</td>\n",
       "      <td>Undirected</td>\n",
       "      <td>3.397895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>193</td>\n",
       "      <td>211</td>\n",
       "      <td>Undirected</td>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>211</td>\n",
       "      <td>10458</td>\n",
       "      <td>Undirected</td>\n",
       "      <td>1.693147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SOURCE  TARGET        TYPE    WEIGHT\n",
       "0      32     211  Undirected  2.098612\n",
       "1      55     211  Undirected  1.000000\n",
       "2      98     211  Undirected  3.397895\n",
       "3     193     211  Undirected  2.098612\n",
       "4     211   10458  Undirected  1.693147"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old = pd.read_csv(output_path + 'edges.csv')\n",
    "old['WEIGHT'] = old['WEIGHT'].apply(lambda x: (log(x) + 1))\n",
    "# old.to_csv(output_path + 'coauthorships_of_interest.csv.weight-log')\n",
    "old.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the MCL Output to generate Gephi Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCL clusters assigned to authors of [ /mnt/hd0/alberto/Dropbox/ufmg-not-code/datasets/dblp/cn-infocom-clusters/cn/ ]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>top</th>\n",
       "      <th>mcl_cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>H. Vincent Poor</td>\n",
       "      <td>0</td>\n",
       "      <td>1411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Wei Wang</td>\n",
       "      <td>0</td>\n",
       "      <td>1915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Yan Zhang</td>\n",
       "      <td>0</td>\n",
       "      <td>1333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Wei Liu</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>Yang Yang</td>\n",
       "      <td>0</td>\n",
       "      <td>1915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id            label  top  mcl_cluster\n",
       "0   0  H. Vincent Poor    0         1411\n",
       "1   1         Wei Wang    0         1915\n",
       "2   2        Yan Zhang    0         1333\n",
       "3   3          Wei Liu    0            3\n",
       "4  13        Yang Yang    0         1915"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remember to change this accordingly\n",
    "# output_path = mypath + \"cn/\"\n",
    "\n",
    "nodes = pd.read_csv(output_path + \"nodes.csv\")\n",
    "\n",
    "with open(output_path + 'mcl_output.txt') as f:        \n",
    "    for line in f.readlines():               \n",
    "        authors = [int(x) for x in line.split()]\n",
    "        cluster_id = int(authors[0])\n",
    "        nodes.ix[nodes['id'].isin(authors), 'mcl_cluster'] = cluster_id \n",
    "        \n",
    "print(\"MCL clusters assigned to authors of [\", output_path, \"]\")\n",
    "\n",
    "nodes[['id', 'label', 'top', 'mcl_cluster']].to_csv(output_path + \"nodes.csv\", index=False)     \n",
    "nodes.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
